{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resampledata.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOqrtYxGI2x3K2W06HpEFzd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yohanesnuwara/machine-learning/blob/master/03_resampling/resampledata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8b-ywHh7v5K",
        "colab_type": "text"
      },
      "source": [
        "# **Algorithm Evaluation Methods Using Resampling**\n",
        "\n",
        "The goal of resampling methods is to make the best use of your training data in order to accurately estimate the performance of a model on new unseen data.\n",
        "\n",
        "1. Train and test split\n",
        "2. k-fold cross-validation split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQhHJKlR521m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "7d48e3e8-752d-40fe-f3a2-24746ace79e0"
      },
      "source": [
        "!git clone https://github.com/yohanesnuwara/machine-learning"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'machine-learning'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/81)\u001b[K\rremote: Counting objects:   2% (2/81)\u001b[K\rremote: Counting objects:   3% (3/81)\u001b[K\rremote: Counting objects:   4% (4/81)\u001b[K\rremote: Counting objects:   6% (5/81)\u001b[K\rremote: Counting objects:   7% (6/81)\u001b[K\rremote: Counting objects:   8% (7/81)\u001b[K\rremote: Counting objects:   9% (8/81)\u001b[K\rremote: Counting objects:  11% (9/81)\u001b[K\rremote: Counting objects:  12% (10/81)\u001b[K\rremote: Counting objects:  13% (11/81)\u001b[K\rremote: Counting objects:  14% (12/81)\u001b[K\rremote: Counting objects:  16% (13/81)\u001b[K\rremote: Counting objects:  17% (14/81)\u001b[K\rremote: Counting objects:  18% (15/81)\u001b[K\rremote: Counting objects:  19% (16/81)\u001b[K\rremote: Counting objects:  20% (17/81)\u001b[K\rremote: Counting objects:  22% (18/81)\u001b[K\rremote: Counting objects:  23% (19/81)\u001b[K\rremote: Counting objects:  24% (20/81)\u001b[K\rremote: Counting objects:  25% (21/81)\u001b[K\rremote: Counting objects:  27% (22/81)\u001b[K\rremote: Counting objects:  28% (23/81)\u001b[K\rremote: Counting objects:  29% (24/81)\u001b[K\rremote: Counting objects:  30% (25/81)\u001b[K\rremote: Counting objects:  32% (26/81)\u001b[K\rremote: Counting objects:  33% (27/81)\u001b[K\rremote: Counting objects:  34% (28/81)\u001b[K\rremote: Counting objects:  35% (29/81)\u001b[K\rremote: Counting objects:  37% (30/81)\u001b[K\rremote: Counting objects:  38% (31/81)\u001b[K\rremote: Counting objects:  39% (32/81)\u001b[K\rremote: Counting objects:  40% (33/81)\u001b[K\rremote: Counting objects:  41% (34/81)\u001b[K\rremote: Counting objects:  43% (35/81)\u001b[K\rremote: Counting objects:  44% (36/81)\u001b[K\rremote: Counting objects:  45% (37/81)\u001b[K\rremote: Counting objects:  46% (38/81)\u001b[K\rremote: Counting objects:  48% (39/81)\u001b[K\rremote: Counting objects:  49% (40/81)\u001b[K\rremote: Counting objects:  50% (41/81)\u001b[K\rremote: Counting objects:  51% (42/81)\u001b[K\rremote: Counting objects:  53% (43/81)\u001b[K\rremote: Counting objects:  54% (44/81)\u001b[K\rremote: Counting objects:  55% (45/81)\u001b[K\rremote: Counting objects:  56% (46/81)\u001b[K\rremote: Counting objects:  58% (47/81)\u001b[K\rremote: Counting objects:  59% (48/81)\u001b[K\rremote: Counting objects:  60% (49/81)\u001b[K\rremote: Counting objects:  61% (50/81)\u001b[K\rremote: Counting objects:  62% (51/81)\u001b[K\rremote: Counting objects:  64% (52/81)\u001b[K\rremote: Counting objects:  65% (53/81)\u001b[K\rremote: Counting objects:  66% (54/81)\u001b[K\rremote: Counting objects:  67% (55/81)\u001b[K\rremote: Counting objects:  69% (56/81)\u001b[K\rremote: Counting objects:  70% (57/81)\u001b[K\rremote: Counting objects:  71% (58/81)\u001b[K\rremote: Counting objects:  72% (59/81)\u001b[K\rremote: Counting objects:  74% (60/81)\u001b[K\rremote: Counting objects:  75% (61/81)\u001b[K\rremote: Counting objects:  76% (62/81)\u001b[K\rremote: Counting objects:  77% (63/81)\u001b[K\rremote: Counting objects:  79% (64/81)\u001b[K\rremote: Counting objects:  80% (65/81)\u001b[K\rremote: Counting objects:  81% (66/81)\u001b[K\rremote: Counting objects:  82% (67/81)\u001b[K\rremote: Counting objects:  83% (68/81)\u001b[K\rremote: Counting objects:  85% (69/81)\u001b[K\rremote: Counting objects:  86% (70/81)\u001b[K\rremote: Counting objects:  87% (71/81)\u001b[K\rremote: Counting objects:  88% (72/81)\u001b[K\rremote: Counting objects:  90% (73/81)\u001b[K\rremote: Counting objects:  91% (74/81)\u001b[K\rremote: Counting objects:  92% (75/81)\u001b[K\rremote: Counting objects:  93% (76/81)\u001b[K\rremote: Counting objects:  95% (77/81)\u001b[K\rremote: Counting objects:  96% (78/81)\u001b[K\rremote: Counting objects:  97% (79/81)\u001b[K\rremote: Counting objects:  98% (80/81)\u001b[K\rremote: Counting objects: 100% (81/81)\u001b[K\rremote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/78)\u001b[K\rremote: Compressing objects:   2% (2/78)\u001b[K\rremote: Compressing objects:   3% (3/78)\u001b[K\rremote: Compressing objects:   5% (4/78)\u001b[K\rremote: Compressing objects:   6% (5/78)\u001b[K\rremote: Compressing objects:   7% (6/78)\u001b[K\rremote: Compressing objects:   8% (7/78)\u001b[K\rremote: Compressing objects:  10% (8/78)\u001b[K\rremote: Compressing objects:  11% (9/78)\u001b[K\rremote: Compressing objects:  12% (10/78)\u001b[K\rremote: Compressing objects:  14% (11/78)\u001b[K\rremote: Compressing objects:  15% (12/78)\u001b[K\rremote: Compressing objects:  16% (13/78)\u001b[K\rremote: Compressing objects:  17% (14/78)\u001b[K\rremote: Compressing objects:  19% (15/78)\u001b[K\rremote: Compressing objects:  20% (16/78)\u001b[K\rremote: Compressing objects:  21% (17/78)\u001b[K\rremote: Compressing objects:  23% (18/78)\u001b[K\rremote: Compressing objects:  24% (19/78)\u001b[K\rremote: Compressing objects:  25% (20/78)\u001b[K\rremote: Compressing objects:  26% (21/78)\u001b[K\rremote: Compressing objects:  28% (22/78)\u001b[K\rremote: Compressing objects:  29% (23/78)\u001b[K\rremote: Compressing objects:  30% (24/78)\u001b[K\rremote: Compressing objects:  32% (25/78)\u001b[K\rremote: Compressing objects:  33% (26/78)\u001b[K\rremote: Compressing objects:  34% (27/78)\u001b[K\rremote: Compressing objects:  35% (28/78)\u001b[K\rremote: Compressing objects:  37% (29/78)\u001b[K\rremote: Compressing objects:  38% (30/78)\u001b[K\rremote: Compressing objects:  39% (31/78)\u001b[K\rremote: Compressing objects:  41% (32/78)\u001b[K\rremote: Compressing objects:  42% (33/78)\u001b[K\rremote: Compressing objects:  43% (34/78)\u001b[K\rremote: Compressing objects:  44% (35/78)\u001b[K\rremote: Compressing objects:  46% (36/78)\u001b[K\rremote: Compressing objects:  47% (37/78)\u001b[K\rremote: Compressing objects:  48% (38/78)\u001b[K\rremote: Compressing objects:  50% (39/78)\u001b[K\rremote: Compressing objects:  51% (40/78)\u001b[K\rremote: Compressing objects:  52% (41/78)\u001b[K\rremote: Compressing objects:  53% (42/78)\u001b[K\rremote: Compressing objects:  55% (43/78)\u001b[K\rremote: Compressing objects:  56% (44/78)\u001b[K\rremote: Compressing objects:  57% (45/78)\u001b[K\rremote: Compressing objects:  58% (46/78)\u001b[K\rremote: Compressing objects:  60% (47/78)\u001b[K\rremote: Compressing objects:  61% (48/78)\u001b[K\rremote: Compressing objects:  62% (49/78)\u001b[K\rremote: Compressing objects:  64% (50/78)\u001b[K\rremote: Compressing objects:  65% (51/78)\u001b[K\rremote: Compressing objects:  66% (52/78)\u001b[K\rremote: Compressing objects:  67% (53/78)\u001b[K\rremote: Compressing objects:  69% (54/78)\u001b[K\rremote: Compressing objects:  70% (55/78)\u001b[K\rremote: Compressing objects:  71% (56/78)\u001b[K\rremote: Compressing objects:  73% (57/78)\u001b[K\rremote: Compressing objects:  74% (58/78)\u001b[K\rremote: Compressing objects:  75% (59/78)\u001b[K\rremote: Compressing objects:  76% (60/78)\u001b[K\rremote: Compressing objects:  78% (61/78)\u001b[K\rremote: Compressing objects:  79% (62/78)\u001b[K\rremote: Compressing objects:  80% (63/78)\u001b[K\rremote: Compressing objects:  82% (64/78)\u001b[K\rremote: Compressing objects:  83% (65/78)\u001b[K\rremote: Compressing objects:  84% (66/78)\u001b[K\rremote: Compressing objects:  85% (67/78)\u001b[K\rremote: Compressing objects:  87% (68/78)\u001b[K\rremote: Compressing objects:  88% (69/78)\u001b[K\rremote: Compressing objects:  89% (70/78)\u001b[K\rremote: Compressing objects:  91% (71/78)\u001b[K\rremote: Compressing objects:  92% (72/78)\u001b[K\rremote: Compressing objects:  93% (73/78)\u001b[K\rremote: Compressing objects:  94% (74/78)\u001b[K\rremote: Compressing objects:  96% (75/78)\u001b[K\rremote: Compressing objects:  97% (76/78)\u001b[K\rremote: Compressing objects:  98% (77/78)\u001b[K\rremote: Compressing objects: 100% (78/78)\u001b[K\rremote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "Unpacking objects:   1% (1/81)   \rUnpacking objects:   2% (2/81)   \rUnpacking objects:   3% (3/81)   \rUnpacking objects:   4% (4/81)   \rUnpacking objects:   6% (5/81)   \rUnpacking objects:   7% (6/81)   \rUnpacking objects:   8% (7/81)   \rUnpacking objects:   9% (8/81)   \rUnpacking objects:  11% (9/81)   \rUnpacking objects:  12% (10/81)   \rUnpacking objects:  13% (11/81)   \rUnpacking objects:  14% (12/81)   \rUnpacking objects:  16% (13/81)   \rUnpacking objects:  17% (14/81)   \rUnpacking objects:  18% (15/81)   \rUnpacking objects:  19% (16/81)   \rUnpacking objects:  20% (17/81)   \rUnpacking objects:  22% (18/81)   \rUnpacking objects:  23% (19/81)   \rUnpacking objects:  24% (20/81)   \rUnpacking objects:  25% (21/81)   \rUnpacking objects:  27% (22/81)   \rUnpacking objects:  28% (23/81)   \rUnpacking objects:  29% (24/81)   \rUnpacking objects:  30% (25/81)   \rUnpacking objects:  32% (26/81)   \rUnpacking objects:  33% (27/81)   \rUnpacking objects:  34% (28/81)   \rUnpacking objects:  35% (29/81)   \rUnpacking objects:  37% (30/81)   \rUnpacking objects:  38% (31/81)   \rUnpacking objects:  39% (32/81)   \rUnpacking objects:  40% (33/81)   \rUnpacking objects:  41% (34/81)   \rUnpacking objects:  43% (35/81)   \rUnpacking objects:  44% (36/81)   \rUnpacking objects:  45% (37/81)   \rUnpacking objects:  46% (38/81)   \rUnpacking objects:  48% (39/81)   \rUnpacking objects:  49% (40/81)   \rUnpacking objects:  50% (41/81)   \rUnpacking objects:  51% (42/81)   \rUnpacking objects:  53% (43/81)   \rUnpacking objects:  54% (44/81)   \rUnpacking objects:  55% (45/81)   \rUnpacking objects:  56% (46/81)   \rUnpacking objects:  58% (47/81)   \rUnpacking objects:  59% (48/81)   \rUnpacking objects:  60% (49/81)   \rUnpacking objects:  61% (50/81)   \rUnpacking objects:  62% (51/81)   \rUnpacking objects:  64% (52/81)   \rUnpacking objects:  65% (53/81)   \rUnpacking objects:  66% (54/81)   \rUnpacking objects:  67% (55/81)   \rUnpacking objects:  69% (56/81)   \rUnpacking objects:  70% (57/81)   \rUnpacking objects:  71% (58/81)   \rUnpacking objects:  72% (59/81)   \rUnpacking objects:  74% (60/81)   \rUnpacking objects:  75% (61/81)   \rUnpacking objects:  76% (62/81)   \rUnpacking objects:  77% (63/81)   \rUnpacking objects:  79% (64/81)   \rUnpacking objects:  80% (65/81)   \rUnpacking objects:  81% (66/81)   \rUnpacking objects:  82% (67/81)   \rUnpacking objects:  83% (68/81)   \rUnpacking objects:  85% (69/81)   \rUnpacking objects:  86% (70/81)   \rUnpacking objects:  87% (71/81)   \rUnpacking objects:  88% (72/81)   \rUnpacking objects:  90% (73/81)   \rUnpacking objects:  91% (74/81)   \rUnpacking objects:  92% (75/81)   \rremote: Total 81 (delta 32), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  93% (76/81)   \rUnpacking objects:  95% (77/81)   \rUnpacking objects:  96% (78/81)   \rUnpacking objects:  97% (79/81)   \rUnpacking objects:  98% (80/81)   \rUnpacking objects: 100% (81/81)   \rUnpacking objects: 100% (81/81), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U3gbW--721i",
        "colab_type": "text"
      },
      "source": [
        "## Resampling Method 1: Train and test split\n",
        "\n",
        "Splitting dataset into train and test datasets by **split percentage**. Good default split 0.6 (60% of dataset as train and 40% as test dataset). \n",
        "\n",
        "**Limitation**: get a noisy estimate of\n",
        "algorithm performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM0HfStYNJ4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split a dataset into a train and test set\n",
        "def train_test_split(dataset, split=0.60):\n",
        "  from random import randrange\n",
        "  train = list()\n",
        "  train_size = split * len(dataset)\n",
        "  dataset_copy = list(dataset)\n",
        "  while len(train) < train_size:\n",
        "    index = randrange(len(dataset_copy))\n",
        "    train.append(dataset_copy.pop(index))\n",
        "  return train, dataset_copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMmTb_ujOQoW",
        "colab_type": "text"
      },
      "source": [
        "Implement the function to a dataset consists of 10 rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15nXWEdCOWGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ffceb970-a5bc-4d58-a897-1496590cb93a"
      },
      "source": [
        "from random import seed\n",
        "\n",
        "# test train/test split\n",
        "seed(1)\n",
        "dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n",
        "train, test = train_test_split(dataset)\n",
        "print(train)\n",
        "print(test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3], [2], [7], [1], [8], [9]]\n",
            "[[4], [5], [6], [10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y6fgFy9Ozqb",
        "colab_type": "text"
      },
      "source": [
        "## Resampling Method 2: k-fold Cross-Validation Split\n",
        "\n",
        "Splitting dataset into `k` groups (or folds), then the algorithm is trained, evaluated `k` times, and taking the mean performance score. Value of `k` is chosen to split the dataset, good default `k = 3` for small dataset and `k = 10` for larger dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPHu1nZ8O5G7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split a dataset into $k$ folds\n",
        "def cross_validation_split(dataset, folds=3):\n",
        "  from random import randrange\n",
        "  dataset_split = list()\n",
        "  dataset_copy = list(dataset)\n",
        "  fold_size = int(len(dataset) / folds)\n",
        "  for i in range(folds):\n",
        "    fold = list()\n",
        "    while len(fold) < fold_size:\n",
        "      index = randrange(len(dataset_copy))\n",
        "      fold.append(dataset_copy.pop(index))\n",
        "    dataset_split.append(fold)\n",
        "  return dataset_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imHJQ5_pRvzC",
        "colab_type": "text"
      },
      "source": [
        "Implement the function to a dataset consists of 10 rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPkUd4D1Ripg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8469aae0-92e6-4456-a37e-b8a708564ddc"
      },
      "source": [
        "from random import seed\n",
        "\n",
        "# test cross validation split\n",
        "seed(1)\n",
        "dataset = [[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]]\n",
        "folds = cross_validation_split(dataset, 3)\n",
        "print(folds)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[3], [2], [7]], [[1], [8], [9]], [[10], [6], [5]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_2cGJR7XBR9",
        "colab_type": "text"
      },
      "source": [
        "# Resampling Method using `scikit-klearn`\n",
        "\n",
        "Resource: [Machine Learning Mastery](https://machinelearningmastery.com/evaluate-performance-machine-learning-algorithms-python-using-resampling/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8TPeTUYXcWu",
        "colab_type": "text"
      },
      "source": [
        "## Train-Test Split\n",
        "\n",
        "Implement to `pima-indians-diabetes` dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z7FadkOXfCL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "0b0cd88b-710f-4be1-afbc-f1f558fd8d55"
      },
      "source": [
        "# Evaluate using a train and a test set\n",
        "import pandas\n",
        "\n",
        "url = \"/content/machine-learning/datasets/pima-indians-diabetes.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "dataframe = pandas.read_csv(url, names=names)\n",
        "dataframe"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preg</th>\n",
              "      <th>plas</th>\n",
              "      <th>pres</th>\n",
              "      <th>skin</th>\n",
              "      <th>test</th>\n",
              "      <th>mass</th>\n",
              "      <th>pedi</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     preg  plas  pres  skin  test  mass   pedi  age  class\n",
              "0       6   148    72    35     0  33.6  0.627   50      1\n",
              "1       1    85    66    29     0  26.6  0.351   31      0\n",
              "2       8   183    64     0     0  23.3  0.672   32      1\n",
              "3       1    89    66    23    94  28.1  0.167   21      0\n",
              "4       0   137    40    35   168  43.1  2.288   33      1\n",
              "..    ...   ...   ...   ...   ...   ...    ...  ...    ...\n",
              "763    10   101    76    48   180  32.9  0.171   63      0\n",
              "764     2   122    70    27     0  36.8  0.340   27      0\n",
              "765     5   121    72    23   112  26.2  0.245   30      0\n",
              "766     1   126    60     0     0  30.1  0.349   47      1\n",
              "767     1    93    70    31     0  30.4  0.315   23      0\n",
              "\n",
              "[768 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-XLgI4adOdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "2dcc35cd-3e95-4bc5-e66f-b287396de5ca"
      },
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "array = dataframe.values\n",
        "X = array[:,0:8] \n",
        "Y = array[:,8] # the class column (consisting of 0 and 1) is the function\n",
        "test_size = 0.33\n",
        "seed = 7\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "result = model.score(X_test, Y_test)\n",
        "print(\"Accuracy: %.3f%%\" % (result*100.0))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 78.740%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0D_6u1rfHQK",
        "colab_type": "text"
      },
      "source": [
        "## k-fold Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrYqHl4yfM8j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "outputId": "17efce17-01f4-4147-bed6-b3dd019a922c"
      },
      "source": [
        "num_instances = len(X)\n",
        "seed = 7\n",
        "kfold = model_selection.KFold(n_splits=6, random_state=seed)\n",
        "model = LogisticRegression()\n",
        "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
        "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 76.953% (4.053%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d_sNpPRhCFf",
        "colab_type": "text"
      },
      "source": [
        "## Repeated Train-Test Split\n",
        "\n",
        "Another variation on k-fold cross validation is to create a random split of the data like the train/test split described above, but repeat the process of splitting and evaluation of the algorithm multiple times, like cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exO7co-XhiMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unsuccessful\n",
        "# Evaluate using Shuffle Split Cross Validation\n",
        "\n",
        "num_samples = 5\n",
        "test_size = 0.33\n",
        "num_instances = len(X)\n",
        "seed = 7\n",
        "kfold = model_selection.ShuffleSplit(n_splits=10, test_size=test_size, random_state=seed)\n",
        "model = LogisticRegression()\n",
        "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
        "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZWZ_cRUf9CM",
        "colab_type": "text"
      },
      "source": [
        "## Leave One Out Cross Validation (LOOCV)\n",
        "\n",
        "You can configure cross validation so that the size of the fold is 1 (k is set to the number of observations in your dataset). This variation of cross validation is called leave-one-out cross validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ccO5QyagQ9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unsuccessful\n",
        "\n",
        "num_folds = 10\n",
        "num_instances = len(X)\n",
        "loocv = model_selection.LeaveOneOut()\n",
        "model = LogisticRegression()\n",
        "results = model_selection.cross_val_score(model, X, Y, cv=loocv)\n",
        "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}