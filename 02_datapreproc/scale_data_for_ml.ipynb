{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scale_data_for_ml.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPP16BHopQA1GiqcYaxPTZd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yohanesnuwara/machine-learning/blob/master/02_datapreproc/scale_data_for_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p6hSV04jKL9",
        "colab_type": "text"
      },
      "source": [
        "# **Scale Machine Learning Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPALIuy1ju1h",
        "colab_type": "code",
        "outputId": "c7584838-492e-4b99-f06b-4c81a1ea88ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!git clone https://github.com/yohanesnuwara/machine-learning"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'machine-learning'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/47)\u001b[K\rremote: Counting objects:   4% (2/47)\u001b[K\rremote: Counting objects:   6% (3/47)\u001b[K\rremote: Counting objects:   8% (4/47)\u001b[K\rremote: Counting objects:  10% (5/47)\u001b[K\rremote: Counting objects:  12% (6/47)\u001b[K\rremote: Counting objects:  14% (7/47)\u001b[K\rremote: Counting objects:  17% (8/47)\u001b[K\rremote: Counting objects:  19% (9/47)\u001b[K\rremote: Counting objects:  21% (10/47)\u001b[K\rremote: Counting objects:  23% (11/47)\u001b[K\rremote: Counting objects:  25% (12/47)\u001b[K\rremote: Counting objects:  27% (13/47)\u001b[K\rremote: Counting objects:  29% (14/47)\u001b[K\rremote: Counting objects:  31% (15/47)\u001b[K\rremote: Counting objects:  34% (16/47)\u001b[K\rremote: Counting objects:  36% (17/47)\u001b[K\rremote: Counting objects:  38% (18/47)\u001b[K\rremote: Counting objects:  40% (19/47)\u001b[K\rremote: Counting objects:  42% (20/47)\u001b[K\rremote: Counting objects:  44% (21/47)\u001b[K\rremote: Counting objects:  46% (22/47)\u001b[K\rremote: Counting objects:  48% (23/47)\u001b[K\rremote: Counting objects:  51% (24/47)\u001b[K\rremote: Counting objects:  53% (25/47)\u001b[K\rremote: Counting objects:  55% (26/47)\u001b[K\rremote: Counting objects:  57% (27/47)\u001b[K\rremote: Counting objects:  59% (28/47)\u001b[K\rremote: Counting objects:  61% (29/47)\u001b[K\rremote: Counting objects:  63% (30/47)\u001b[K\rremote: Counting objects:  65% (31/47)\u001b[K\rremote: Counting objects:  68% (32/47)\u001b[K\rremote: Counting objects:  70% (33/47)\u001b[K\rremote: Counting objects:  72% (34/47)\u001b[K\rremote: Counting objects:  74% (35/47)\u001b[K\rremote: Counting objects:  76% (36/47)\u001b[K\rremote: Counting objects:  78% (37/47)\u001b[K\rremote: Counting objects:  80% (38/47)\u001b[K\rremote: Counting objects:  82% (39/47)\u001b[K\rremote: Counting objects:  85% (40/47)\u001b[K\rremote: Counting objects:  87% (41/47)\u001b[K\rremote: Counting objects:  89% (42/47)\u001b[K\rremote: Counting objects:  91% (43/47)\u001b[K\rremote: Counting objects:  93% (44/47)\u001b[K\rremote: Counting objects:  95% (45/47)\u001b[K\rremote: Counting objects:  97% (46/47)\u001b[K\rremote: Counting objects: 100% (47/47)\u001b[K\rremote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects:   2% (1/44)\u001b[K\rremote: Compressing objects:   4% (2/44)\u001b[K\rremote: Compressing objects:   6% (3/44)\u001b[K\rremote: Compressing objects:   9% (4/44)\u001b[K\rremote: Compressing objects:  11% (5/44)\u001b[K\rremote: Compressing objects:  13% (6/44)\u001b[K\rremote: Compressing objects:  15% (7/44)\u001b[K\rremote: Compressing objects:  18% (8/44)\u001b[K\rremote: Compressing objects:  20% (9/44)\u001b[K\rremote: Compressing objects:  22% (10/44)\u001b[K\rremote: Compressing objects:  25% (11/44)\u001b[K\rremote: Compressing objects:  27% (12/44)\u001b[K\rremote: Compressing objects:  29% (13/44)\u001b[K\rremote: Compressing objects:  31% (14/44)\u001b[K\rremote: Compressing objects:  34% (15/44)\u001b[K\rremote: Compressing objects:  36% (16/44)\u001b[K\rremote: Compressing objects:  38% (17/44)\u001b[K\rremote: Compressing objects:  40% (18/44)\u001b[K\rremote: Compressing objects:  43% (19/44)\u001b[K\rremote: Compressing objects:  45% (20/44)\u001b[K\rremote: Compressing objects:  47% (21/44)\u001b[K\rremote: Compressing objects:  50% (22/44)\u001b[K\rremote: Compressing objects:  52% (23/44)\u001b[K\rremote: Compressing objects:  54% (24/44)\u001b[K\rremote: Compressing objects:  56% (25/44)\u001b[K\rremote: Compressing objects:  59% (26/44)\u001b[K\rremote: Compressing objects:  61% (27/44)\u001b[K\rremote: Compressing objects:  63% (28/44)\u001b[K\rremote: Compressing objects:  65% (29/44)\u001b[K\rremote: Compressing objects:  68% (30/44)\u001b[K\rremote: Compressing objects:  70% (31/44)\u001b[K\rremote: Compressing objects:  72% (32/44)\u001b[K\rremote: Compressing objects:  75% (33/44)\u001b[K\rremote: Compressing objects:  77% (34/44)\u001b[K\rremote: Compressing objects:  79% (35/44)\u001b[K\rremote: Compressing objects:  81% (36/44)\u001b[K\rremote: Compressing objects:  84% (37/44)\u001b[K\rremote: Compressing objects:  86% (38/44)\u001b[K\rremote: Compressing objects:  88% (39/44)\u001b[K\rremote: Compressing objects:  90% (40/44)\u001b[K\rremote: Compressing objects:  93% (41/44)\u001b[K\rremote: Compressing objects:  95% (42/44)\u001b[K\rremote: Compressing objects:  97% (43/44)\u001b[K\rremote: Compressing objects: 100% (44/44)\u001b[K\rremote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "Unpacking objects:   2% (1/47)   \rUnpacking objects:   4% (2/47)   \rUnpacking objects:   6% (3/47)   \rUnpacking objects:   8% (4/47)   \rUnpacking objects:  10% (5/47)   \rUnpacking objects:  12% (6/47)   \rUnpacking objects:  14% (7/47)   \rUnpacking objects:  17% (8/47)   \rUnpacking objects:  19% (9/47)   \rUnpacking objects:  21% (10/47)   \rUnpacking objects:  23% (11/47)   \rUnpacking objects:  25% (12/47)   \rUnpacking objects:  27% (13/47)   \rUnpacking objects:  29% (14/47)   \rUnpacking objects:  31% (15/47)   \rUnpacking objects:  34% (16/47)   \rUnpacking objects:  36% (17/47)   \rUnpacking objects:  38% (18/47)   \rUnpacking objects:  40% (19/47)   \rUnpacking objects:  42% (20/47)   \rUnpacking objects:  44% (21/47)   \rUnpacking objects:  46% (22/47)   \rUnpacking objects:  48% (23/47)   \rUnpacking objects:  51% (24/47)   \rUnpacking objects:  53% (25/47)   \rUnpacking objects:  55% (26/47)   \rUnpacking objects:  57% (27/47)   \rUnpacking objects:  59% (28/47)   \rUnpacking objects:  61% (29/47)   \rUnpacking objects:  63% (30/47)   \rUnpacking objects:  65% (31/47)   \rUnpacking objects:  68% (32/47)   \rUnpacking objects:  70% (33/47)   \rUnpacking objects:  72% (34/47)   \rUnpacking objects:  74% (35/47)   \rUnpacking objects:  76% (36/47)   \rUnpacking objects:  78% (37/47)   \rUnpacking objects:  80% (38/47)   \rUnpacking objects:  82% (39/47)   \rUnpacking objects:  85% (40/47)   \rUnpacking objects:  87% (41/47)   \rremote: Total 47 (delta 14), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  89% (42/47)   \rUnpacking objects:  91% (43/47)   \rUnpacking objects:  93% (44/47)   \rUnpacking objects:  95% (45/47)   \rUnpacking objects:  97% (46/47)   \rUnpacking objects: 100% (47/47)   \rUnpacking objects: 100% (47/47), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9I26wVijTAR",
        "colab_type": "text"
      },
      "source": [
        "## Normalize data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ5DEVxnjn1o",
        "colab_type": "text"
      },
      "source": [
        "Find minimum and maximum value of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEb_RKTuj8Eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "  minmax = list()\n",
        "  for i in range(len(dataset[0])):\n",
        "    col_values = [row[i] for row in dataset]\n",
        "    value_min = min(col_values)\n",
        "    value_max = max(col_values)\n",
        "    minmax.append([value_min, value_max])\n",
        "  return minmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN2vDYG0lxMD",
        "colab_type": "code",
        "outputId": "d5baa009-82a4-4294-cf15-69ef9a45bb9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Small dataset example (2 columns and 4 rows)\n",
        "dataset = [[50, 30], [20, 90], [40, 10], [5, 10]]\n",
        "# Calculate min and max for each column\n",
        "minmax = dataset_minmax(dataset)\n",
        "print(minmax)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5, 50], [10, 90]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCJShmuFmlpi",
        "colab_type": "text"
      },
      "source": [
        "Normalize min to 0 and max to 1. Equation to normalize:\n",
        "\n",
        "$$scaled value = \\frac{value - min}{max - min}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg1q1F3qmEKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "  for row in dataset:\n",
        "    for i in range(len(row)):\n",
        "      row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__6rWzAen66f",
        "colab_type": "code",
        "outputId": "cb71c4ae-b7dd-4df2-9a8e-d530a3f7643c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Normalize columns\n",
        "normalize_dataset(dataset, minmax)\n",
        "print(dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0, 0.25], [0.3333333333333333, 1.0], [0.7777777777777778, 0.0], [0.0, 0.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwRKGXORocbS",
        "colab_type": "text"
      },
      "source": [
        "Load (using function library in folder `01_dataload`) and normalize `pima-indians-diabetes` dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cfzkdFnojtC",
        "colab_type": "code",
        "outputId": "9e5619a8-f06e-4c06-b341-73032f7a4775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import os, sys\n",
        "sys.path.append('/content/machine-learning/01_dataload')\n",
        "\n",
        "from load_csv_data import *\n",
        "\n",
        "# Load pima-indians-diabetes dataset\n",
        "filename = '/content/machine-learning/datasets/pima-indians-diabetes.csv'\n",
        "dataset = load_csv(filename)\n",
        "\n",
        "# convert string columns to float\n",
        "for i in range(len(dataset[0])):\n",
        "  str_column_to_float(dataset, i)\n",
        "print('Original dataset:', dataset[0])\n",
        "\n",
        "# Calculate min and max for each column\n",
        "minmax = dataset_minmax(dataset)\n",
        "# Normalize columns\n",
        "normalize_dataset(dataset, minmax)\n",
        "print('Normalized dataset:', dataset[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original dataset: [6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0, 1.0]\n",
            "Normalized dataset: [0.35294117647058826, 0.7437185929648241, 0.5901639344262295, 0.35353535353535354, 0.0, 0.5007451564828614, 0.23441502988898377, 0.48333333333333334, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGG6h3AKremr",
        "colab_type": "text"
      },
      "source": [
        "## Standardize data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duuK7qDHrtM9",
        "colab_type": "text"
      },
      "source": [
        "Centering the distribution of the data on the value 0 and the standard deviation to the value 1. Using mean and standard deviation to summarize a normal distribution. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk-Ly0n3XM5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate mean\n",
        "def mean(numbers):\n",
        "  return sum(numbers)/float(len(numbers))\n",
        "\n",
        "# Calculate column mean\n",
        "def column_mean(dataset):\n",
        "  mean_col = [(mean(column)) for column in zip(*dataset)]\n",
        "  # del(mean_col[-1])\n",
        "  return mean_col\n",
        "\n",
        "# Calculate the standard deviation of a list of numbers\n",
        "def stdev(numbers):\n",
        "  from math import sqrt\n",
        "  avg = mean(numbers)\n",
        "  variance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
        "  return sqrt(variance)\n",
        "\n",
        "# Calculate column standard deviation\n",
        "def column_stdev(dataset):\n",
        "  stdev_col = [(stdev(column)) for column in zip(*dataset)]\n",
        "  # del(stdev_col[-1])\n",
        "  return stdev_col"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxUcuAEvstwz",
        "colab_type": "text"
      },
      "source": [
        "Calculate `mean` and `standard deviation` of the simple dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1ALoqhFXWMl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fafb5dfc-3e23-4b40-c1eb-6b9d6907ad92"
      },
      "source": [
        "# simple dataset (2 columns and 3 rows)\n",
        "dataset = [[50, 30], [20, 90], [30, 50]]\n",
        "means = column_mean(dataset)\n",
        "stdevs = column_stdev(dataset)\n",
        "print('Mean of column 1:', means[0], 'and column 2:', means[1])\n",
        "print('Standard deviation of column 1:', stdevs[0], 'and column 2:', stdevs[1])"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of column 1: 33.333333333333336 and column 2: 56.666666666666664\n",
            "Standard deviation of column 1: 15.275252316519467 and column 2: 30.550504633038933\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKkJc76Mt1Tv",
        "colab_type": "text"
      },
      "source": [
        "Standardize the dataset based on the equation:\n",
        "\n",
        "$$standardizedvalue(i) = \\frac{\\sum_{i=1}^{n}(value(i) - mean)}{stdev}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwYMSD08tRqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# standardize dataset\n",
        "def standardize_dataset(dataset, means, stdevs):\n",
        "  for row in dataset:\n",
        "    for i in range(len(row)):\n",
        "      row[i] = (row[i] - means[i]) / stdevs[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ulHOMQ7ukZV",
        "colab_type": "code",
        "outputId": "f92f5271-c2bd-4cde-ffa1-38f9c5ea74d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# standardize dataset\n",
        "standardize_dataset(dataset, means, stdevs)\n",
        "print('Standardized dataset:', dataset)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Standardized dataset: [[1.0910894511799618, -0.8728715609439694], [-0.8728715609439697, 1.091089451179962], [-0.21821789023599253, -0.2182178902359923]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9Lq-KtqwgWl",
        "colab_type": "text"
      },
      "source": [
        "Implement to `pima-indians-diabetes` dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toi-Qi0YwjTx",
        "colab_type": "code",
        "outputId": "83b1923d-0d3a-4ddb-f849-c756016ac982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Load pima-indians-diabetes dataset\n",
        "filename = '/content/machine-learning/datasets/pima-indians-diabetes.csv'\n",
        "dataset = load_csv(filename)\n",
        "print('Loaded data file {0} with {1} rows and {2} columns'.format(filename, len(dataset), len(dataset[0])))\n",
        "\n",
        "# convert string columns to float\n",
        "for i in range(len(dataset[0])):\n",
        "  str_column_to_float(dataset, i)\n",
        "print('Original dataset:', dataset[0])\n",
        "\n",
        "# Estimate mean and standard deviation\n",
        "means = column_mean(dataset)\n",
        "stdevs = column_stdev(dataset)\n",
        "\n",
        "# standardize dataset\n",
        "standardize_dataset(dataset, means, stdevs)\n",
        "print('Standardized dataset:', dataset[0])"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded data file /content/machine-learning/datasets/pima-indians-diabetes.csv with 768 rows and 9 columns\n",
            "Original dataset: [6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0, 1.0]\n",
            "Standardized dataset: [0.6395304921176576, 0.8477713205896718, 0.14954329852954296, 0.9066790623472505, -0.692439324724129, 0.2038799072674717, 0.468186870229798, 1.4250667195933604, 1.3650063669598067]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lKbC4lEdkdo",
        "colab_type": "text"
      },
      "source": [
        "## Extension: Other data transform techniques\n",
        "\n",
        "* Exponential transform (logarithm, exponents, square root)\n",
        "* Power transforms e.g. Box-Cox to fix skew in normally distributed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxIDfGy2d_yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}